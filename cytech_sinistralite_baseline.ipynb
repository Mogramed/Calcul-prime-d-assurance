{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a527efa5",
   "metadata": {},
   "source": [
    "# CY Tech 2026 — Prediction de la sinistralité (baseline robuste)\n",
    "Objectif: prédire une **prime** (coût attendu) via une approche **2-parties** :\n",
    "- **Fréquence** : $p(x)=P(\text{sinistre}>0 \\mid x)$\n",
    "- **Gravité** : $m(x)=E[\text{montant}\\mid \text{sinistre}>0, x]$\n",
    "\n",
    "Prime prédite : $\\hat{prime}(x)=\\hat{p}(x)\\times\\hat{m}(x)$\n",
    "\n",
    "Ce notebook inclut :\n",
    "- EDA rapide\n",
    "- split **anti-fuite** (GroupKFold sur `id_client`)\n",
    "- split **type production** (Group + temps basé sur `index` si pertinent)\n",
    "- baseline CatBoost + hooks pour calibration & smearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d2db5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (50000, 33)\n",
      "Test : (50000, 28)\n",
      "Sample submission cols: ['index', 'pred']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id_client</th>\n",
       "      <th>id_vehicule</th>\n",
       "      <th>id_contrat</th>\n",
       "      <th>bonus</th>\n",
       "      <th>type_contrat</th>\n",
       "      <th>duree_contrat</th>\n",
       "      <th>anciennete_info</th>\n",
       "      <th>freq_paiement</th>\n",
       "      <th>paiement</th>\n",
       "      <th>...</th>\n",
       "      <th>marque_vehicule</th>\n",
       "      <th>modele_vehicule</th>\n",
       "      <th>debut_vente_vehicule</th>\n",
       "      <th>fin_vente_vehicule</th>\n",
       "      <th>vitesse_vehicule</th>\n",
       "      <th>type_vehicule</th>\n",
       "      <th>prix_vehicule</th>\n",
       "      <th>poids_vehicule</th>\n",
       "      <th>nombre_sinistres</th>\n",
       "      <th>montant_sinistre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A00000001</td>\n",
       "      <td>V01</td>\n",
       "      <td>A00000001-V01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Maxi</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>Biannual</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>PEUGEOT</td>\n",
       "      <td>306</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>182</td>\n",
       "      <td>Tourism</td>\n",
       "      <td>20700</td>\n",
       "      <td>1210</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A00000002</td>\n",
       "      <td>V01</td>\n",
       "      <td>A00000002-V01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Maxi</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Biannual</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>MERCEDES BENZ</td>\n",
       "      <td>C220</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>229</td>\n",
       "      <td>Tourism</td>\n",
       "      <td>34250</td>\n",
       "      <td>1510</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A00000003</td>\n",
       "      <td>V01</td>\n",
       "      <td>A00000003-V01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Maxi</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Yearly</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>BMW</td>\n",
       "      <td>Z3</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>210</td>\n",
       "      <td>Tourism</td>\n",
       "      <td>28661</td>\n",
       "      <td>1270</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A00000004</td>\n",
       "      <td>V01</td>\n",
       "      <td>A00000004-V01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Median2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Yearly</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>VOLKSWAGEN</td>\n",
       "      <td>GOLF</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>180</td>\n",
       "      <td>Tourism</td>\n",
       "      <td>14407</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A00000005</td>\n",
       "      <td>V01</td>\n",
       "      <td>A00000005-V01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Maxi</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>Biannual</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>RENAULT</td>\n",
       "      <td>LAGUNA</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>195</td>\n",
       "      <td>Tourism</td>\n",
       "      <td>16770</td>\n",
       "      <td>1230</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id_client id_vehicule     id_contrat  bonus type_contrat  \\\n",
       "0      0  A00000001         V01  A00000001-V01    0.5         Maxi   \n",
       "1      1  A00000002         V01  A00000002-V01    0.5         Maxi   \n",
       "2      2  A00000003         V01  A00000003-V01    0.5         Maxi   \n",
       "3      3  A00000004         V01  A00000004-V01    0.5      Median2   \n",
       "4      4  A00000005         V01  A00000005-V01    0.5         Maxi   \n",
       "\n",
       "   duree_contrat  anciennete_info freq_paiement paiement  ... marque_vehicule  \\\n",
       "0             29                9      Biannual       No  ...         PEUGEOT   \n",
       "1              3                1      Biannual       No  ...   MERCEDES BENZ   \n",
       "2              2                2        Yearly       No  ...             BMW   \n",
       "3             22                1        Yearly       No  ...      VOLKSWAGEN   \n",
       "4             16                4      Biannual       No  ...         RENAULT   \n",
       "\n",
       "  modele_vehicule debut_vente_vehicule  fin_vente_vehicule  vitesse_vehicule  \\\n",
       "0             306                   10                   9               182   \n",
       "1            C220                    4                   2               229   \n",
       "2              Z3                   12                  11               210   \n",
       "3            GOLF                   18                  15               180   \n",
       "4          LAGUNA                   13                  11               195   \n",
       "\n",
       "  type_vehicule prix_vehicule  poids_vehicule  nombre_sinistres  \\\n",
       "0       Tourism         20700            1210                 0   \n",
       "1       Tourism         34250            1510                 0   \n",
       "2       Tourism         28661            1270                 0   \n",
       "3       Tourism         14407            1020                 0   \n",
       "4       Tourism         16770            1230                 0   \n",
       "\n",
       "   montant_sinistre  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_PATH = \"train.csv\"\n",
    "TEST_PATH  = \"test.csv\"\n",
    "SUB_PATH   = \"prime_pred_sandbox.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)\n",
    "sub_ex = pd.read_csv(SUB_PATH)\n",
    "\n",
    "print(\"Train:\", train.shape)\n",
    "print(\"Test :\", test.shape)\n",
    "print(\"Sample submission cols:\", list(sub_ex.columns))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1603f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 27\n",
      "n_cat: 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Colonnes\n",
    "target_amount = \"montant_sinistre\"\n",
    "target_freq   = \"nombre_sinistres\"  # ici c'est 0/1 (vérifié)\n",
    "group_col     = \"id_client\"\n",
    "id_col        = \"index\"\n",
    "\n",
    "# Features communes train/test (on exclut l'id)\n",
    "common_cols = [c for c in train.columns if c in test.columns]\n",
    "feature_cols = [c for c in common_cols if c != id_col]\n",
    "\n",
    "# Categorical\n",
    "cat_cols = [c for c in feature_cols if train[c].dtype == \"object\"]\n",
    "\n",
    "print(\"n_features:\", len(feature_cols))\n",
    "print(\"n_cat:\", len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bebc2b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim rate: 0.05834\n",
      "Cost mean: 103.369344 | max: 21826.96\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cibles\n",
    "y_freq = (train[target_amount] > 0).astype(int)\n",
    "y_cost = train[target_amount].astype(float)\n",
    "\n",
    "print(\"Claim rate:\", y_freq.mean())\n",
    "print(\"Cost mean:\", y_cost.mean(), \"| max:\", y_cost.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4471b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex_conducteur2        0.66812\n",
       "anciennete_vehicule    0.00002\n",
       "bonus                  0.00000\n",
       "anciennete_info        0.00000\n",
       "freq_paiement          0.00000\n",
       "paiement               0.00000\n",
       "utilisation            0.00000\n",
       "code_postal            0.00000\n",
       "conducteur2            0.00000\n",
       "type_contrat           0.00000\n",
       "duree_contrat          0.00000\n",
       "age_conducteur2        0.00000\n",
       "age_conducteur1        0.00000\n",
       "anciennete_permis1     0.00000\n",
       "sex_conducteur1        0.00000\n",
       "anciennete_permis2     0.00000\n",
       "cylindre_vehicule      0.00000\n",
       "din_vehicule           0.00000\n",
       "essence_vehicule       0.00000\n",
       "marque_vehicule        0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Missingness utile (on s'attend à beaucoup de NA sur sex_conducteur2)\n",
    "miss = train[feature_cols].isna().mean().sort_values(ascending=False)\n",
    "miss.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771fd3f",
   "metadata": {},
   "source": [
    "## Prétraitements \"métier\" simples\n",
    "- Si `conducteur2 == \"No\"` : `age_conducteur2` et `anciennete_permis2` à NA (au lieu de 0)\n",
    "- Valeurs 0 \"techniques\" : `poids_vehicule==0` et `cylindre_vehicule==0` -> NA\n",
    "- CatBoost n'accepte pas NaN dans les variables catégorielles : on remplace par \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f6a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_for_catboost(df: pd.DataFrame, feature_cols: list[str], cat_cols: list[str]) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    if \"conducteur2\" in df.columns:\n",
    "        mask_no = df[\"conducteur2\"].astype(str).str.lower().eq(\"no\")\n",
    "        for col in [\"age_conducteur2\", \"anciennete_permis2\"]:\n",
    "            if col in df.columns:\n",
    "                df.loc[mask_no, col] = np.nan\n",
    "\n",
    "    for col in [\"poids_vehicule\", \"cylindre_vehicule\"]:\n",
    "        if col in df.columns:\n",
    "            df.loc[df[col] == 0, col] = np.nan\n",
    "\n",
    "    # Cat -> str + NA token\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].where(df[col].notna(), \"NA\").astype(str)\n",
    "\n",
    "    return df[feature_cols]\n",
    "\n",
    "X_train = preprocess_for_catboost(train, feature_cols, cat_cols)\n",
    "X_test  = preprocess_for_catboost(test,  feature_cols, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e87cce1",
   "metadata": {},
   "source": [
    "## Split 1 — Anti-fuite (GroupKFold sur `id_client`)\n",
    "Recommandé si des clients apparaissent plusieurs fois (c'est le cas ici)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a4dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def group_kfold_splits(train_df: pd.DataFrame, n_splits=5):\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    groups = train_df[group_col].values\n",
    "    for fold, (tr_idx, va_idx) in enumerate(gkf.split(train_df, y_freq, groups)):\n",
    "        yield fold, tr_idx, va_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a301c5",
   "metadata": {},
   "source": [
    "## Split 2 — \"production\" (Group + temps)\n",
    "Si `index` reflète un ordre temporel (train=passé, test=futur), ce split est souvent plus proche du Kaggle private.\n",
    "\n",
    "Principe:\n",
    "- on associe à chaque `id_client` un **temps** (ex: max index du client)\n",
    "- on trie les clients par ce temps\n",
    "- on fait un split *forward-chaining* (train sur le passé, val sur une fenêtre du futur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ba686b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " array([    0,     1,     2, ..., 10007, 10008, 10009], shape=(10010,)),\n",
       " array([10010, 10011, 10012, ..., 20004, 20005, 20006], shape=(9997,)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def group_time_splits(train_df: pd.DataFrame, n_splits=5):\n",
    "    # temps du groupe = max index (modifiable: mean, last, etc.)\n",
    "    grp_time = train_df.groupby(group_col)[id_col].max().sort_values()\n",
    "    groups_sorted = grp_time.index.to_numpy()\n",
    "\n",
    "    fold_sizes = np.full(n_splits, len(groups_sorted)//n_splits, dtype=int)\n",
    "    fold_sizes[:len(groups_sorted)%n_splits] += 1\n",
    "\n",
    "    current = 0\n",
    "    folds = []\n",
    "    for fs in fold_sizes:\n",
    "        folds.append(groups_sorted[current:current+fs])\n",
    "        current += fs\n",
    "\n",
    "    # forward chaining\n",
    "    for fold in range(1, n_splits):\n",
    "        val_groups = folds[fold]\n",
    "        train_groups = np.concatenate(folds[:fold])\n",
    "        tr_idx = train_df.index[train_df[group_col].isin(train_groups)].to_numpy()\n",
    "        va_idx = train_df.index[train_df[group_col].isin(val_groups)].to_numpy()\n",
    "        yield fold, tr_idx, va_idx\n",
    "\n",
    "# Exemple\n",
    "next(group_time_splits(train, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf988c0f",
   "metadata": {},
   "source": [
    "## Modèles — baseline CatBoost (freq + sev(log))\n",
    "Hooks:\n",
    "- calibration proba (isotonic / platt) sur les prédictions OOF\n",
    "- smearing (Duan) pour corriger le biais du retour log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5dcd10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def fit_predict_two_part(\n",
    "    X_train, y_freq, y_cost, cat_cols,\n",
    "    tr_idx, va_idx,\n",
    "    seed=42,\n",
    "    freq_params=None,\n",
    "    sev_params=None,\n",
    "    use_smearing=True\n",
    "):\n",
    "    freq_params = freq_params or dict(\n",
    "        loss_function=\"Logloss\",\n",
    "        iterations=3000,\n",
    "        learning_rate=0.03,\n",
    "        depth=7,\n",
    "        l2_leaf_reg=6,\n",
    "        random_seed=seed,\n",
    "        verbose=False,\n",
    "        od_type=\"Iter\",\n",
    "        od_wait=200,\n",
    "    )\n",
    "    sev_params = sev_params or dict(\n",
    "        loss_function=\"RMSE\",\n",
    "        iterations=6000,\n",
    "        learning_rate=0.03,\n",
    "        depth=8,\n",
    "        l2_leaf_reg=8,\n",
    "        random_seed=seed,\n",
    "        verbose=False,\n",
    "        od_type=\"Iter\",\n",
    "        od_wait=300,\n",
    "    )\n",
    "\n",
    "    X_tr, X_va = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "    y_trf, y_vaf = y_freq.iloc[tr_idx], y_freq.iloc[va_idx]\n",
    "\n",
    "    # 1) Fréquence\n",
    "    clf = CatBoostClassifier(**freq_params)\n",
    "    clf.fit(Pool(X_tr, y_trf, cat_features=cat_cols),\n",
    "            eval_set=Pool(X_va, y_vaf, cat_features=cat_cols),\n",
    "            use_best_model=True)\n",
    "    p_va = clf.predict_proba(Pool(X_va, cat_features=cat_cols))[:, 1]\n",
    "\n",
    "    # 2) Gravité (sur sinistrés du train fold)\n",
    "    pos_tr = y_trf.values == 1\n",
    "    X_tr_pos = X_tr.loc[pos_tr]\n",
    "    y_tr_sev = np.log1p(y_cost.iloc[tr_idx].values[pos_tr])\n",
    "\n",
    "    reg = CatBoostRegressor(**sev_params)\n",
    "    reg.fit(Pool(X_tr_pos, y_tr_sev, cat_features=cat_cols),\n",
    "            eval_set=Pool(X_va, np.zeros(len(X_va)), cat_features=cat_cols),\n",
    "            use_best_model=True)\n",
    "\n",
    "    z_va = reg.predict(Pool(X_va, cat_features=cat_cols))\n",
    "    m_va = np.expm1(z_va)\n",
    "\n",
    "    # Smearing: corrige le biais exp()\n",
    "    if use_smearing:\n",
    "        z_tr_pos = reg.predict(Pool(X_tr_pos, cat_features=cat_cols))\n",
    "        resid = y_tr_sev - z_tr_pos\n",
    "        smear = float(np.mean(np.exp(resid)))\n",
    "        m_va = smear * np.exp(z_va) - 1.0\n",
    "        m_va = np.maximum(m_va, 0.0)\n",
    "\n",
    "    prime_va = p_va * m_va\n",
    "    return prime_va, clf, reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "443f66c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 RMSE: 492.7022\n",
      "Fold 2 RMSE: 610.8778\n",
      "Fold 3 RMSE: 546.0255\n",
      "Fold 4 RMSE: 514.5740\n",
      "\n",
      "OOF RMSE: 544.9952769107592\n",
      "Fold mean ± std: 541.0449020356975 44.55101173346713\n",
      "Baseline RMSE si pred=0: 555.106812072628\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Choisis un splitter:\n",
    "# SPLITTER = group_kfold_splits\n",
    "SPLITTER = group_time_splits\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "fold_scores = []\n",
    "\n",
    "for fold, tr_idx, va_idx in SPLITTER(train, n_splits=5):\n",
    "    prime_va, _, _ = fit_predict_two_part(\n",
    "        X_train, y_freq, y_cost, cat_cols,\n",
    "        tr_idx, va_idx,\n",
    "        seed=42+fold,\n",
    "        use_smearing=True\n",
    "    )\n",
    "    oof[va_idx] = prime_va\n",
    "    score = rmse(y_cost.iloc[va_idx], prime_va)\n",
    "    fold_scores.append(score)\n",
    "    print(f\"Fold {fold} RMSE: {score:.4f}\")\n",
    "\n",
    "print(\"\\nOOF RMSE:\", rmse(y_cost, oof))\n",
    "print(\"Fold mean ± std:\", float(np.mean(fold_scores)), float(np.std(fold_scores)))\n",
    "print(\"Baseline RMSE si pred=0:\", rmse(y_cost, np.zeros_like(oof)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384deec0",
   "metadata": {},
   "source": [
    "## Calibration de la fréquence (optionnel mais souvent rentable)\n",
    "À appliquer en **cross-fit** :\n",
    "- récupérer les proba OOF du modèle fréquence\n",
    "- fitter un calibrateur (isotonic ou logistic)\n",
    "- recalibrer les proba test\n",
    "\n",
    "⚠️ Ne pas fitter le calibrateur sur les mêmes points que ceux qu’on évalue (sinon fuite)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "982f1002",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input should have at least 1 dimension i.e. satisfy `len(x.shape) > 0`, got scalar `array(544.99527691)` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m oof_proba = \u001b[32m544.9952769107592\u001b[39m\n\u001b[32m      6\u001b[39m iso = IsotonicRegression(out_of_bounds=\u001b[33m\"\u001b[39m\u001b[33mclip\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43miso\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43moof_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_freq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m p_calib = iso.transform(oof_proba)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\icemo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\icemo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\isotonic.py:391\u001b[39m, in \u001b[36mIsotonicRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fit the model using X, y as training data.\u001b[39;00m\n\u001b[32m    364\u001b[39m \n\u001b[32m    365\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    388\u001b[39m \u001b[33;03mnew input data.\u001b[39;00m\n\u001b[32m    389\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    390\u001b[39m check_params = \u001b[38;5;28mdict\u001b[39m(accept_sparse=\u001b[38;5;28;01mFalse\u001b[39;00m, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    394\u001b[39m y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, dtype=X.dtype, **check_params)\n\u001b[32m    395\u001b[39m check_consistent_length(X, y, sample_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\icemo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1095\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1090\u001b[39m             array = _asarray_with_order(\n\u001b[32m   1091\u001b[39m                 array, dtype=dtype, order=order, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, xp=xp\n\u001b[32m   1092\u001b[39m             )\n\u001b[32m   1094\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1095\u001b[39m     n_samples = \u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1096\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m   1097\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1098\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1099\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1100\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1101\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\icemo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:390\u001b[39m, in \u001b[36m_num_samples\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x.shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x.shape) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    391\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInput should have at least 1 dimension i.e. satisfy \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    392\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`len(x.shape) > 0`, got scalar `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    393\u001b[39m         )\n\u001b[32m    394\u001b[39m     \u001b[38;5;66;03m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[32m    395\u001b[39m     \u001b[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x.shape[\u001b[32m0\u001b[39m], numbers.Integral):\n",
      "\u001b[31mTypeError\u001b[39m: Input should have at least 1 dimension i.e. satisfy `len(x.shape) > 0`, got scalar `array(544.99527691)` instead."
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# Exemple: calibration sur OOF (à adapter si tu stockes aussi les oof proba)\n",
    "# Ici on illustre la mécanique si tu as `oof_proba`.\n",
    "oof_proba = 544.9952769107592\n",
    "iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "iso.fit(oof_proba, y_freq)\n",
    "p_calib = iso.transform(oof_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a4accf",
   "metadata": {},
   "source": [
    "## Entraînement final + submission\n",
    "On refit sur *tout* le train, puis on prédit sur test, et on écrit un CSV au format de `prime_pred_sandbox.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f3054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6566592\ttotal: 55.3ms\tremaining: 3m 41s\n",
      "200:\tlearn: 0.2104486\ttotal: 16.3s\tremaining: 5m 8s\n",
      "400:\tlearn: 0.2055354\ttotal: 34.3s\tremaining: 5m 7s\n",
      "600:\tlearn: 0.2013752\ttotal: 52.5s\tremaining: 4m 57s\n",
      "800:\tlearn: 0.1960677\ttotal: 1m 10s\tremaining: 4m 43s\n",
      "1000:\tlearn: 0.1912715\ttotal: 1m 29s\tremaining: 4m 28s\n",
      "1200:\tlearn: 0.1871842\ttotal: 1m 48s\tremaining: 4m 12s\n",
      "1400:\tlearn: 0.1831123\ttotal: 2m 7s\tremaining: 3m 56s\n",
      "1600:\tlearn: 0.1794798\ttotal: 2m 26s\tremaining: 3m 39s\n",
      "1800:\tlearn: 0.1755710\ttotal: 2m 45s\tremaining: 3m 21s\n",
      "2000:\tlearn: 0.1721246\ttotal: 3m 3s\tremaining: 3m 3s\n",
      "2200:\tlearn: 0.1685516\ttotal: 3m 22s\tremaining: 2m 45s\n",
      "2400:\tlearn: 0.1651896\ttotal: 3m 41s\tremaining: 2m 27s\n",
      "2600:\tlearn: 0.1618124\ttotal: 4m\tremaining: 2m 9s\n",
      "2800:\tlearn: 0.1583717\ttotal: 4m 18s\tremaining: 1m 50s\n",
      "3000:\tlearn: 0.1546821\ttotal: 4m 37s\tremaining: 1m 32s\n",
      "3200:\tlearn: 0.1511783\ttotal: 4m 56s\tremaining: 1m 14s\n",
      "3400:\tlearn: 0.1481290\ttotal: 5m 15s\tremaining: 55.6s\n",
      "3600:\tlearn: 0.1448397\ttotal: 5m 34s\tremaining: 37.1s\n",
      "3800:\tlearn: 0.1417553\ttotal: 5m 53s\tremaining: 18.5s\n",
      "3999:\tlearn: 0.1385744\ttotal: 6m 12s\tremaining: 0us\n",
      "0:\tlearn: 0.5921009\ttotal: 34.4ms\tremaining: 3m 26s\n",
      "200:\tlearn: 0.5477217\ttotal: 5.75s\tremaining: 2m 45s\n",
      "400:\tlearn: 0.5158036\ttotal: 11.8s\tremaining: 2m 44s\n",
      "600:\tlearn: 0.4826654\ttotal: 18.1s\tremaining: 2m 42s\n",
      "800:\tlearn: 0.4533285\ttotal: 24.5s\tremaining: 2m 39s\n",
      "1000:\tlearn: 0.4294038\ttotal: 33.2s\tremaining: 2m 45s\n",
      "1200:\tlearn: 0.4059047\ttotal: 40s\tremaining: 2m 39s\n",
      "1400:\tlearn: 0.3847813\ttotal: 46.7s\tremaining: 2m 33s\n",
      "1600:\tlearn: 0.3641447\ttotal: 53.3s\tremaining: 2m 26s\n",
      "1800:\tlearn: 0.3460108\ttotal: 1m\tremaining: 2m 20s\n",
      "2000:\tlearn: 0.3288739\ttotal: 1m 6s\tremaining: 2m 13s\n",
      "2200:\tlearn: 0.3126534\ttotal: 1m 13s\tremaining: 2m 6s\n",
      "2400:\tlearn: 0.2955431\ttotal: 1m 19s\tremaining: 1m 59s\n",
      "2600:\tlearn: 0.2801444\ttotal: 1m 26s\tremaining: 1m 52s\n",
      "2800:\tlearn: 0.2648514\ttotal: 1m 32s\tremaining: 1m 46s\n",
      "3000:\tlearn: 0.2503446\ttotal: 1m 39s\tremaining: 1m 39s\n",
      "3200:\tlearn: 0.2364110\ttotal: 1m 45s\tremaining: 1m 32s\n",
      "3400:\tlearn: 0.2246724\ttotal: 1m 52s\tremaining: 1m 25s\n",
      "3600:\tlearn: 0.2136652\ttotal: 1m 58s\tremaining: 1m 18s\n",
      "3800:\tlearn: 0.2023834\ttotal: 2m 4s\tremaining: 1m 12s\n",
      "4000:\tlearn: 0.1927851\ttotal: 2m 11s\tremaining: 1m 5s\n",
      "4200:\tlearn: 0.1831783\ttotal: 2m 17s\tremaining: 58.9s\n",
      "4400:\tlearn: 0.1735999\ttotal: 2m 23s\tremaining: 52.3s\n",
      "4600:\tlearn: 0.1656928\ttotal: 2m 30s\tremaining: 45.6s\n",
      "4800:\tlearn: 0.1573048\ttotal: 2m 36s\tremaining: 39.1s\n",
      "5000:\tlearn: 0.1497783\ttotal: 2m 42s\tremaining: 32.5s\n",
      "5200:\tlearn: 0.1428493\ttotal: 2m 49s\tremaining: 26s\n",
      "5400:\tlearn: 0.1364330\ttotal: 2m 55s\tremaining: 19.4s\n",
      "5600:\tlearn: 0.1299691\ttotal: 3m 1s\tremaining: 12.9s\n",
      "5800:\tlearn: 0.1239501\ttotal: 3m 8s\tremaining: 6.45s\n",
      "5999:\tlearn: 0.1176956\ttotal: 3m 14s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>46.621052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50001</td>\n",
       "      <td>36.674278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50002</td>\n",
       "      <td>212.121064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50003</td>\n",
       "      <td>115.535895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50004</td>\n",
       "      <td>26.412856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        pred\n",
       "0  50000   46.621052\n",
       "1  50001   36.674278\n",
       "2  50002  212.121064\n",
       "3  50003  115.535895\n",
       "4  50004   26.412856"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Refit final (à partir des paramètres qui marchent bien en CV)\n",
    "freq_params = dict(\n",
    "    loss_function=\"Logloss\",\n",
    "    iterations=4000,\n",
    "    learning_rate=0.03,\n",
    "    depth=7,\n",
    "    l2_leaf_reg=6,\n",
    "    random_seed=42,\n",
    "    verbose=200,\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=300,\n",
    ")\n",
    "\n",
    "sev_params = dict(\n",
    "    loss_function=\"RMSE\",\n",
    "    iterations=6000,\n",
    "    learning_rate=0.03,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=8,\n",
    "    random_seed=42,\n",
    "    verbose=200,\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=400,\n",
    ")\n",
    "\n",
    "# 1) fréquence\n",
    "clf = CatBoostClassifier(**freq_params)\n",
    "clf.fit(Pool(X_train, y_freq, cat_features=cat_cols))\n",
    "\n",
    "p_test = clf.predict_proba(Pool(X_test, cat_features=cat_cols))[:, 1]\n",
    "\n",
    "# 2) gravité\n",
    "pos = y_freq.values == 1\n",
    "y_sev = np.log1p(y_cost.values[pos])\n",
    "\n",
    "reg = CatBoostRegressor(**sev_params)\n",
    "reg.fit(Pool(X_train.loc[pos], y_sev, cat_features=cat_cols))\n",
    "\n",
    "z_test = reg.predict(Pool(X_test, cat_features=cat_cols))\n",
    "\n",
    "# smearing sur tout le train pos\n",
    "z_tr = reg.predict(Pool(X_train.loc[pos], cat_features=cat_cols))\n",
    "smear = float(np.mean(np.exp(y_sev - z_tr)))\n",
    "\n",
    "m_test = smear * np.exp(z_test) - 1.0\n",
    "m_test = np.maximum(m_test, 0.0)\n",
    "\n",
    "prime_test = p_test * m_test\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"index\": test[id_col].astype(int),\n",
    "    \"pred\": prime_test.astype(float)\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
