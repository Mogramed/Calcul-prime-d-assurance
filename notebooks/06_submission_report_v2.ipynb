{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b242303a",
      "metadata": {},
      "source": [
        "# 06 - Submission report V2.1\n",
        "\n",
        "Refit 100% train (sans holdout 90/10), calibration/tail safe,\n",
        "generation de:\n",
        "- `submission_v2_robust.csv`\n",
        "- `submission_v2_single.csv`\n",
        "et audit pre-submission.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bb9471a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ROOT = Path.cwd()\n",
        "if not (ROOT / \"src\").exists():\n",
        "    ROOT = ROOT.parent\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "from src.v2_pipeline import (\n",
        "    DEFAULT_V2_DIR,\n",
        "    ensure_dir,\n",
        "    load_train_test,\n",
        "    prepare_feature_sets,\n",
        "    fit_full_predict_fulltrain,\n",
        "    fit_calibrator,\n",
        "    apply_calibrator,\n",
        "    fit_tail_mapper_safe,\n",
        "    apply_tail_mapper_safe,\n",
        "    build_submission,\n",
        "    compute_prediction_distribution_audit,\n",
        "    V2_COARSE_CONFIGS,\n",
        ")\n",
        "\n",
        "ARTIFACT_V2 = ensure_dir(ROOT / DEFAULT_V2_DIR)\n",
        "DATA_DIR = ROOT / \"data\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d530d808",
      "metadata": {},
      "outputs": [],
      "source": [
        "run_df = pd.read_csv(ARTIFACT_V2 / \"run_registry_v2.csv\")\n",
        "oof = pd.read_parquet(ARTIFACT_V2 / \"oof_predictions_v2.parquet\")\n",
        "selected = pd.read_csv(ARTIFACT_V2 / \"selected_models_v2.csv\")\n",
        "ens_meta = json.loads((ARTIFACT_V2 / \"ensemble_weights_v2.json\").read_text(encoding=\"utf-8\"))\n",
        "\n",
        "train_raw, test_raw = load_train_test(DATA_DIR)\n",
        "feature_sets = prepare_feature_sets(train_raw, test_raw, rare_min_count=30, drop_identifiers=True)\n",
        "\n",
        "cfg_lookup = {\n",
        "    engine: {cfg[\"config_id\"]: cfg for cfg in cfgs}\n",
        "    for engine, cfgs in V2_COARSE_CONFIGS.items()\n",
        "}\n",
        "\n",
        "dist_audit_path = ARTIFACT_V2 / \"pred_distribution_audit_v2.csv\"\n",
        "dist_audit = pd.read_csv(dist_audit_path) if dist_audit_path.exists() else pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "02d57d20",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generated predictions for runs: 6\n"
          ]
        }
      ],
      "source": [
        "preds = {}\n",
        "for _, row in selected.iterrows():\n",
        "    run_id = row[\"run_id\"]\n",
        "    engine = row[\"engine\"]\n",
        "    fs_name = row[\"feature_set\"]\n",
        "    family = row[\"family\"]\n",
        "    tweedie_power = float(row.get(\"tweedie_power\", 1.5))\n",
        "    config_id = row[\"config_id\"]\n",
        "    seed = int(row[\"seed\"])\n",
        "    severity_mode = row[\"severity_mode\"]\n",
        "    calibration = row[\"calibration\"]\n",
        "    tail_mapper_name = row[\"tail_mapper\"]\n",
        "\n",
        "    cfg = cfg_lookup[engine][config_id]\n",
        "    bundle = feature_sets[fs_name]\n",
        "\n",
        "    spec = {\n",
        "        \"engine\": engine,\n",
        "        \"family\": family,\n",
        "        \"severity_mode\": severity_mode,\n",
        "        \"tweedie_power\": tweedie_power,\n",
        "        \"config_id\": config_id,\n",
        "        \"freq_params\": cfg[\"freq_params\"],\n",
        "        \"sev_params\": cfg[\"sev_params\"],\n",
        "        \"direct_params\": cfg[\"direct_params\"],\n",
        "        \"use_target_encoding\": True,\n",
        "        \"target_encode_cols\": [\"code_postal\", \"cp3\", \"modele_vehicule\", \"marque_modele\"],\n",
        "        \"target_encoding_smoothing\": 20.0,\n",
        "    }\n",
        "\n",
        "    out = fit_full_predict_fulltrain(spec=spec, bundle=bundle, seed=seed, complexity={})\n",
        "    test_freq = out[\"test_freq\"].copy()\n",
        "    test_sev = out[\"test_sev\"].copy()\n",
        "\n",
        "    o = oof[(oof[\"is_test\"] == 0) & (oof[\"split\"] == \"primary_time\") & (oof[\"run_id\"] == run_id)].copy()\n",
        "\n",
        "    if calibration != \"none\" and len(o):\n",
        "        ok = o[\"pred_freq\"].notna()\n",
        "        if ok.any():\n",
        "            cal = fit_calibrator(\n",
        "                o.loc[ok, \"pred_freq\"].to_numpy(),\n",
        "                o.loc[ok, \"y_freq\"].to_numpy(),\n",
        "                method=calibration,\n",
        "            )\n",
        "            test_freq = apply_calibrator(cal, test_freq, method=calibration)\n",
        "\n",
        "    if tail_mapper_name != \"none\" and family != \"direct_tweedie\" and len(o):\n",
        "        pos = (o[\"y_freq\"] == 1) & o[\"pred_sev\"].notna()\n",
        "        if pos.sum() >= 80:\n",
        "            mapper = fit_tail_mapper_safe(\n",
        "                o.loc[pos, \"pred_sev\"].to_numpy(),\n",
        "                o.loc[pos, \"y_sev\"].to_numpy(),\n",
        "            )\n",
        "            sev_before = test_sev.copy()\n",
        "            test_sev = apply_tail_mapper_safe(mapper, test_sev)\n",
        "            std_ratio = float(np.std(test_sev) / max(np.std(sev_before), 1e-9))\n",
        "\n",
        "            q99_oof = float(np.nanquantile(o.loc[pos, \"pred_sev\"].to_numpy(), 0.99))\n",
        "            q99_test = float(np.nanquantile(test_sev, 0.99))\n",
        "            if (std_ratio < 0.70) or (q99_test < 0.60 * q99_oof):\n",
        "                test_sev = sev_before\n",
        "\n",
        "    if family == \"direct_tweedie\":\n",
        "        pred = np.maximum(out[\"test_prime\"], 0.0)\n",
        "    else:\n",
        "        pred = np.maximum(test_freq * test_sev, 0.0)\n",
        "    preds[run_id] = pred\n",
        "\n",
        "print(\"generated predictions for runs:\", len(preds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "eb44ec44",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: c:\\Users\\icemo\\Downloads\\Calcul-prime-d-assurance\\artifacts\\v2\\submission_v2_robust.csv\n",
            "saved: c:\\Users\\icemo\\Downloads\\Calcul-prime-d-assurance\\artifacts\\v2\\submission_v2_single.csv\n"
          ]
        }
      ],
      "source": [
        "strategy = ens_meta.get(\"strategy\", \"single\")\n",
        "run_ids = ens_meta.get(\"run_ids\", list(preds.keys()))\n",
        "weights = ens_meta.get(\"weights\", {})\n",
        "best_single = ens_meta.get(\"best_single_run\", run_ids[0])\n",
        "\n",
        "if strategy == \"ensemble\":\n",
        "    mat = np.column_stack([preds[rid] for rid in run_ids if rid in preds])\n",
        "    used_ids = [rid for rid in run_ids if rid in preds]\n",
        "    w = np.array([weights.get(rid, 0.0) for rid in used_ids], dtype=float)\n",
        "    if w.sum() <= 0:\n",
        "        w = np.full(len(used_ids), 1.0 / len(used_ids))\n",
        "    else:\n",
        "        w = w / w.sum()\n",
        "    pred_robust = mat @ w\n",
        "else:\n",
        "    pred_robust = preds[best_single]\n",
        "\n",
        "pred_single = preds[best_single]\n",
        "\n",
        "sub_robust = build_submission(test_raw[\"index\"], pred_robust)\n",
        "sub_single = build_submission(test_raw[\"index\"], pred_single)\n",
        "\n",
        "sub_robust.to_csv(ARTIFACT_V2 / \"submission_v2_robust.csv\", index=False)\n",
        "sub_single.to_csv(ARTIFACT_V2 / \"submission_v2_single.csv\", index=False)\n",
        "\n",
        "print(\"saved:\", ARTIFACT_V2 / \"submission_v2_robust.csv\")\n",
        "print(\"saved:\", ARTIFACT_V2 / \"submission_v2_single.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7aa4a90a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: c:\\Users\\icemo\\Downloads\\Calcul-prime-d-assurance\\artifacts\\v2\\submission_audit_v2.json\n",
            "saved: c:\\Users\\icemo\\Downloads\\Calcul-prime-d-assurance\\artifacts\\v2\\submission_report_v2.json\n",
            "{'strategy': 'single', 'n_models_selected': 6, 'best_single_run': 'base_v2|catboost|two_part_tweedie|cb_v2_c1|42|weighted_tail|isotonic|isotonic', 'submission_robust': 'c:\\\\Users\\\\icemo\\\\Downloads\\\\Calcul-prime-d-assurance\\\\artifacts\\\\v2\\\\submission_v2_robust.csv', 'submission_single': 'c:\\\\Users\\\\icemo\\\\Downloads\\\\Calcul-prime-d-assurance\\\\artifacts\\\\v2\\\\submission_v2_single.csv', 'submission_audit': 'c:\\\\Users\\\\icemo\\\\Downloads\\\\Calcul-prime-d-assurance\\\\artifacts\\\\v2\\\\submission_audit_v2.json'}\n"
          ]
        }
      ],
      "source": [
        "robust_audit = compute_prediction_distribution_audit(\n",
        "    sub_robust[\"pred\"].to_numpy(),\n",
        "    run_id=\"submission_v2_robust\",\n",
        "    split=\"test\",\n",
        "    sample=\"test\",\n",
        ")\n",
        "single_audit = compute_prediction_distribution_audit(\n",
        "    sub_single[\"pred\"].to_numpy(),\n",
        "    run_id=\"submission_v2_single\",\n",
        "    split=\"test\",\n",
        "    sample=\"test\",\n",
        ")\n",
        "\n",
        "q99_oof_ref = np.nan\n",
        "if not dist_audit.empty:\n",
        "    rr = dist_audit[(dist_audit[\"sample\"] == \"oof\") & (dist_audit[\"split\"] == \"primary_time\")]\n",
        "    rr = rr[rr[\"run_id\"].isin(selected[\"run_id\"].tolist())]\n",
        "    if len(rr):\n",
        "        q99_oof_ref = float(rr[\"pred_q99\"].median())\n",
        "\n",
        "submission_audit = {\n",
        "    \"n_rows_robust\": int(len(sub_robust)),\n",
        "    \"n_rows_single\": int(len(sub_single)),\n",
        "    \"columns_robust\": sub_robust.columns.tolist(),\n",
        "    \"columns_single\": sub_single.columns.tolist(),\n",
        "    \"robust_non_negative\": bool((sub_robust[\"pred\"] >= 0).all()),\n",
        "    \"single_non_negative\": bool((sub_single[\"pred\"] >= 0).all()),\n",
        "    \"robust_no_nan\": bool(sub_robust[\"pred\"].notna().all()),\n",
        "    \"single_no_nan\": bool(sub_single[\"pred\"].notna().all()),\n",
        "    \"robust_distribution\": robust_audit,\n",
        "    \"single_distribution\": single_audit,\n",
        "    \"q99_oof_reference_primary\": None if not np.isfinite(q99_oof_ref) else q99_oof_ref,\n",
        "    \"q99_ratio_robust_test_over_oof_ref\": None if not np.isfinite(q99_oof_ref) else float(robust_audit[\"pred_q99\"] / max(q99_oof_ref, 1e-9)),\n",
        "    \"q99_ratio_single_test_over_oof_ref\": None if not np.isfinite(q99_oof_ref) else float(single_audit[\"pred_q99\"] / max(q99_oof_ref, 1e-9)),\n",
        "}\n",
        "\n",
        "(ARTIFACT_V2 / \"submission_audit_v2.json\").write_text(json.dumps(submission_audit, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "report = {\n",
        "    \"strategy\": strategy,\n",
        "    \"n_models_selected\": int(len(selected)),\n",
        "    \"best_single_run\": best_single,\n",
        "    \"submission_robust\": str(ARTIFACT_V2 / \"submission_v2_robust.csv\"),\n",
        "    \"submission_single\": str(ARTIFACT_V2 / \"submission_v2_single.csv\"),\n",
        "    \"submission_audit\": str(ARTIFACT_V2 / \"submission_audit_v2.json\"),\n",
        "}\n",
        "(ARTIFACT_V2 / \"submission_report_v2.json\").write_text(json.dumps(report, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "print(\"saved:\", ARTIFACT_V2 / \"submission_audit_v2.json\")\n",
        "print(\"saved:\", ARTIFACT_V2 / \"submission_report_v2.json\")\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
