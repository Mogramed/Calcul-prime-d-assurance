{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4904413f",
      "metadata": {},
      "source": [
        "# 01 - EDA + CV design (V2.1)\n",
        "\n",
        "Objectifs:\n",
        "- verifier le data contract train/test,\n",
        "- auditer NA, zeros techniques, distribution cible, extremes,\n",
        "- diagnostiquer le drift/OOD (categoriel + numerique),\n",
        "- valider les 3 splits anti-overfitting,\n",
        "- exporter les diagnostics versionnes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d73a5c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ROOT = Path.cwd()\n",
        "if not (ROOT / \"src\").exists():\n",
        "    ROOT = ROOT.parent\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "from src.v2_pipeline import (\n",
        "    DEFAULT_V2_DIR,\n",
        "    INDEX_COL,\n",
        "    TARGET_SEV_COL,\n",
        "    ensure_dir,\n",
        "    load_train_test,\n",
        "    prepare_feature_sets,\n",
        "    build_split_registry,\n",
        "    validate_folds_disjoint,\n",
        "    validate_group_disjoint,\n",
        "    export_split_artifacts_v2,\n",
        "    compute_ood_diagnostics,\n",
        "    compute_segment_bias_from_oof,\n",
        ")\n",
        "\n",
        "DATA_DIR = ROOT / \"data\"\n",
        "ARTIFACT_V2 = ensure_dir(ROOT / DEFAULT_V2_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c42ac197",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_raw, test_raw = load_train_test(DATA_DIR)\n",
        "feature_sets = prepare_feature_sets(train_raw, test_raw, rare_min_count=30, drop_identifiers=True)\n",
        "bundle = feature_sets[\"base_v2\"]\n",
        "\n",
        "print(\"train shape:\", train_raw.shape, \"test shape:\", test_raw.shape)\n",
        "print(\"feature sets:\", list(feature_sets.keys()))\n",
        "for fs_name, b in feature_sets.items():\n",
        "    print(fs_name, \"features\", len(b.feature_cols), \"cat\", len(b.cat_cols), \"num\", len(b.num_cols))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "535db396",
      "metadata": {},
      "source": [
        "## Data contract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e314aa8c",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_cols = set(train_raw.columns)\n",
        "test_cols = set(test_raw.columns)\n",
        "common_cols = sorted(train_cols.intersection(test_cols))\n",
        "train_only = sorted(train_cols - test_cols)\n",
        "test_only = sorted(test_cols - train_cols)\n",
        "\n",
        "contract = pd.DataFrame(\n",
        "    [\n",
        "        {\"item\": \"train_rows\", \"value\": int(len(train_raw))},\n",
        "        {\"item\": \"test_rows\", \"value\": int(len(test_raw))},\n",
        "        {\"item\": \"common_columns\", \"value\": int(len(common_cols))},\n",
        "        {\"item\": \"train_only_columns\", \"value\": int(len(train_only))},\n",
        "        {\"item\": \"test_only_columns\", \"value\": int(len(test_only))},\n",
        "    ]\n",
        ")\n",
        "display(contract)\n",
        "print(\"train_only:\", train_only)\n",
        "print(\"test_only:\", test_only)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f68796e",
      "metadata": {},
      "source": [
        "## Target, missing values and technical zeros\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "466f15bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "y = train_raw[TARGET_SEV_COL].astype(float)\n",
        "y_pos = y[y > 0]\n",
        "target_stats = pd.DataFrame(\n",
        "    [\n",
        "        {\"metric\": \"n_train\", \"value\": int(len(y))},\n",
        "        {\"metric\": \"claim_rate\", \"value\": float((y > 0).mean())},\n",
        "        {\"metric\": \"mean_positive\", \"value\": float(y_pos.mean()) if len(y_pos) else np.nan},\n",
        "        {\"metric\": \"q95_positive\", \"value\": float(y_pos.quantile(0.95)) if len(y_pos) else np.nan},\n",
        "        {\"metric\": \"q99_positive\", \"value\": float(y_pos.quantile(0.99)) if len(y_pos) else np.nan},\n",
        "        {\"metric\": \"max_positive\", \"value\": float(y_pos.max()) if len(y_pos) else np.nan},\n",
        "    ]\n",
        ")\n",
        "display(target_stats)\n",
        "\n",
        "na_train = train_raw.isna().mean().sort_values(ascending=False).rename(\"na_ratio_train\")\n",
        "na_test = test_raw.isna().mean().sort_values(ascending=False).rename(\"na_ratio_test\")\n",
        "na_table = pd.concat([na_train, na_test], axis=1).fillna(0.0).reset_index().rename(columns={\"index\": \"feature\"})\n",
        "display(na_table.head(20))\n",
        "\n",
        "zero_cols = [c for c in [\"poids_vehicule\", \"cylindre_vehicule\"] if c in train_raw.columns]\n",
        "zero_rows = []\n",
        "for c in zero_cols:\n",
        "    zero_rows.append(\n",
        "        {\n",
        "            \"feature\": c,\n",
        "            \"zero_ratio_train\": float((train_raw[c] == 0).mean()),\n",
        "            \"zero_ratio_test\": float((test_raw[c] == 0).mean()),\n",
        "        }\n",
        "    )\n",
        "display(pd.DataFrame(zero_rows))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efef94ac",
      "metadata": {},
      "source": [
        "## Splits anti-overfitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32f5838e",
      "metadata": {},
      "outputs": [],
      "source": [
        "splits = build_split_registry(train_raw, n_blocks_time=5, n_splits_group=5, group_col=\"id_client\")\n",
        "for split_name, folds in splits.items():\n",
        "    validate_folds_disjoint(\n",
        "        folds,\n",
        "        check_full_coverage=(split_name in {\"secondary_group\", \"aux_blocked5\"}),\n",
        "        n_rows=len(train_raw),\n",
        "    )\n",
        "    if split_name == \"secondary_group\":\n",
        "        validate_group_disjoint(folds, train_raw[\"id_client\"])\n",
        "    print(split_name, {k: (len(v[0]), len(v[1])) for k, v in folds.items()})\n",
        "\n",
        "export_split_artifacts_v2(train=train_raw, splits=splits, output_dir=ARTIFACT_V2)\n",
        "print(\"saved fold artifacts under\", ARTIFACT_V2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d4f2fad",
      "metadata": {},
      "source": [
        "## Drift and OOD diagnostics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e724aa93",
      "metadata": {},
      "outputs": [],
      "source": [
        "ood = compute_ood_diagnostics(bundle.X_train, bundle.X_test)\n",
        "ood_focus = ood[ood[\"feature\"].isin([\"code_postal\", \"cp3\", \"cp2\", \"modele_vehicule\", \"marque_vehicule\", \"marque_modele\"])]\n",
        "display(ood_focus.sort_values(\"unseen_test_levels\", ascending=False))\n",
        "\n",
        "numeric_cols = [c for c in bundle.num_cols if c in bundle.X_test.columns]\n",
        "drift_rows = []\n",
        "for c in numeric_cols:\n",
        "    tr = pd.to_numeric(bundle.X_train[c], errors=\"coerce\")\n",
        "    te = pd.to_numeric(bundle.X_test[c], errors=\"coerce\")\n",
        "    m_tr = float(np.nanmean(tr))\n",
        "    m_te = float(np.nanmean(te))\n",
        "    s_tr = float(np.nanstd(tr))\n",
        "    drift_rows.append(\n",
        "        {\n",
        "            \"diagnostic_type\": \"numeric_drift\",\n",
        "            \"feature\": c,\n",
        "            \"mean_train\": m_tr,\n",
        "            \"mean_test\": m_te,\n",
        "            \"std_train\": s_tr,\n",
        "            \"std_shift\": float((m_te - m_tr) / max(s_tr, 1e-9)),\n",
        "        }\n",
        "    )\n",
        "drift_df = pd.DataFrame(drift_rows).sort_values(\"std_shift\", key=lambda s: s.abs(), ascending=False)\n",
        "display(drift_df.head(20))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b64a81c6",
      "metadata": {},
      "source": [
        "## Segment bias from V1 OOF (if available)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "645f8be4",
      "metadata": {},
      "outputs": [],
      "source": [
        "seg = pd.DataFrame()\n",
        "oof_v1_path = ROOT / \"artifacts\" / \"oof_predictions.parquet\"\n",
        "ens_v1_path = ROOT / \"artifacts\" / \"ensemble_weights_v1.json\"\n",
        "\n",
        "if oof_v1_path.exists():\n",
        "    oof_v1 = pd.read_parquet(oof_v1_path)\n",
        "    if \"run_id\" not in oof_v1.columns:\n",
        "        oof_v1[\"run_id\"] = (\n",
        "            oof_v1[\"engine\"].astype(str) + \"|\"\n",
        "            + oof_v1[\"config_id\"].astype(str) + \"|\"\n",
        "            + oof_v1[\"seed\"].astype(int).astype(str) + \"|\"\n",
        "            + oof_v1[\"severity_mode\"].astype(str) + \"|\"\n",
        "            + oof_v1[\"calibration\"].astype(str)\n",
        "        )\n",
        "    if ens_v1_path.exists():\n",
        "        meta = json.loads(ens_v1_path.read_text(encoding=\"utf-8\"))\n",
        "        run_id = meta.get(\"best_single_run\", oof_v1[\"run_id\"].iloc[0])\n",
        "    else:\n",
        "        run_id = oof_v1[\"run_id\"].iloc[0]\n",
        "    seg = compute_segment_bias_from_oof(train_raw, oof_v1, run_id=run_id, split_name=\"primary_time\")\n",
        "    print(\"segment diagnostics rows:\", len(seg))\n",
        "    display(seg.head(20))\n",
        "else:\n",
        "    print(\"OOF v1 not found, skip segment bias diagnostic.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99d676c5",
      "metadata": {},
      "source": [
        "## Risks and mitigation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7efb013b",
      "metadata": {},
      "outputs": [],
      "source": [
        "risk_table = pd.DataFrame(\n",
        "    [\n",
        "        {\"risk\": \"Fine-grain categorical OOD\", \"impact\": \"Public/private shake-up\", \"mitigation\": \"hierarchy cp2/cp3, robust feature sets\"},\n",
        "        {\"risk\": \"Tail under-dispersion in severity\", \"impact\": \"RMSE degradation\", \"mitigation\": \"safe tail mapper + distribution audit\"},\n",
        "        {\"risk\": \"Client leakage\", \"impact\": \"over-optimistic CV\", \"mitigation\": \"secondary GroupKFold(id_client)\"},\n",
        "        {\"risk\": \"Single split selection bias\", \"impact\": \"unstable ranking\", \"mitigation\": \"primary+secondary+aux weighted selection\"},\n",
        "    ]\n",
        ")\n",
        "display(risk_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f3557e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "diags = []\n",
        "if not ood.empty:\n",
        "    diags.append(ood.assign(diagnostic_type=\"ood\"))\n",
        "if \"drift_df\" in globals() and not drift_df.empty:\n",
        "    diags.append(drift_df)\n",
        "if not seg.empty:\n",
        "    diags.append(seg)\n",
        "diag_all = pd.concat(diags, ignore_index=True, sort=False) if diags else pd.DataFrame()\n",
        "diag_all.to_parquet(ARTIFACT_V2 / \"segment_diagnostics_v2.parquet\", index=False)\n",
        "\n",
        "meta = {\n",
        "    \"n_train\": int(len(train_raw)),\n",
        "    \"n_test\": int(len(test_raw)),\n",
        "    \"feature_sets\": {k: {\"n_features\": len(v.feature_cols), \"n_cat\": len(v.cat_cols)} for k, v in feature_sets.items()},\n",
        "    \"splits\": {k: sorted([int(fid) for fid in v.keys()]) for k, v in splits.items()},\n",
        "    \"train_only_cols\": train_only,\n",
        "    \"test_only_cols\": test_only,\n",
        "}\n",
        "(ARTIFACT_V2 / \"dataset_meta_v2.json\").write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
        "print(\"saved:\", ARTIFACT_V2 / \"segment_diagnostics_v2.parquet\")\n",
        "print(\"saved:\", ARTIFACT_V2 / \"dataset_meta_v2.json\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
