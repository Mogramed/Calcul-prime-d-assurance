{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 01 — EDA + CV Design (V1 robuste anti-overfitting)\n\nObjectifs:\n- Audit données train/test.\n- Feature engineering robuste/stable.\n- Construction de 2 schémas de validation:\n  - `primary_time` (forward-chaining via `index`)\n  - `secondary_group` (`GroupKFold` via `id_client`)\n- Export des artefacts de base pour la modélisation.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import sys\nfrom pathlib import Path\nimport json\nimport numpy as np\nimport pandas as pd\n\nROOT = Path.cwd()\nif not (ROOT / \"src\").exists():\n    ROOT = ROOT.parent\nif str(ROOT) not in sys.path:\n    sys.path.insert(0, str(ROOT))\n\nfrom src.v1_pipeline import (\n    INDEX_COL,\n    TARGET_FREQ_COL,\n    TARGET_SEV_COL,\n    load_train_test,\n    prepare_datasets,\n    build_primary_time_folds,\n    build_secondary_group_folds,\n    validate_folds_disjoint,\n    export_fold_artifacts,\n    ensure_dir,\n)\n\nDATA_DIR = ROOT / \"data\"\nARTIFACT_DIR = ensure_dir(ROOT / \"artifacts\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "train_raw, test_raw = load_train_test(DATA_DIR)\nbundle = prepare_datasets(train_raw, test_raw, drop_identifiers=True)\n\nprint(\"train_raw:\", train_raw.shape)\nprint(\"test_raw :\", test_raw.shape)\nprint(\"X_train  :\", bundle.X_train.shape)\nprint(\"X_test   :\", bundle.X_test.shape)\nprint(\"n_features:\", len(bundle.feature_cols))\nprint(\"n_cat    :\", len(bundle.cat_cols))\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Sanity: target consistency + schema mismatch\nassert TARGET_SEV_COL in train_raw.columns, \"Missing montant_sinistre in train\"\nassert TARGET_FREQ_COL in train_raw.columns, \"Missing nombre_sinistres in train\"\n\nmismatch = sorted(set(bundle.X_train.columns) ^ set(bundle.X_test.columns))\nprint(\"Schema mismatch columns:\", len(mismatch))\nif mismatch:\n    print(mismatch[:20])\n\ntarget_inconsistency = (\n    ((train_raw[TARGET_FREQ_COL] == 0) & (train_raw[TARGET_SEV_COL] > 0)).sum()\n    + ((train_raw[TARGET_FREQ_COL] > 0) & (train_raw[TARGET_SEV_COL] == 0)).sum()\n)\nprint(\"Target inconsistency rows:\", int(target_inconsistency))\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Distribution cible\ny_freq = bundle.y_freq\ny_sev = bundle.y_sev\npos = y_freq == 1\n\nprint(\"Claim rate:\", round(float(y_freq.mean()), 6), f\"({int(pos.sum())}/{len(y_freq)})\")\nprint(\"Severity mean (all):\", round(float(y_sev.mean()), 3))\nprint(\"Severity mean (pos):\", round(float(y_sev[pos].mean()), 3))\nprint(\"Severity max:\", round(float(y_sev.max()), 3))\nfor q in [0.5, 0.75, 0.9, 0.95, 0.99]:\n    print(f\"sev_pos_q{int(q*100):02d}:\", round(float(np.quantile(y_sev[pos], q)), 3))\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Missingness + shift principal sur code_postal\nmissing_top = bundle.X_train.isna().mean().sort_values(ascending=False).head(15)\nprint(\"Top missing rates\")\ndisplay(missing_top.to_frame(\"missing_rate\"))\n\nif \"code_postal\" in bundle.X_train.columns:\n    tr_cp = bundle.X_train[\"code_postal\"].astype(str)\n    te_cp = bundle.X_test[\"code_postal\"].astype(str)\n    unseen_cp = (~te_cp.isin(set(tr_cp))).mean()\n    print(\"Unseen code_postal ratio in test:\", round(float(unseen_cp), 4))\n\nif {\"cp2\", \"cp3\"}.issubset(bundle.X_train.columns):\n    for c in [\"cp2\", \"cp3\"]:\n        tr = bundle.X_train[c].astype(str)\n        te = bundle.X_test[c].astype(str)\n        unseen = (~te.isin(set(tr))).mean()\n        print(f\"Unseen {c} ratio in test:\", round(float(unseen), 4))\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Folds primaires + secondaires\nfolds_primary = build_primary_time_folds(train_raw, n_blocks=5, index_col=INDEX_COL)\nfolds_secondary = build_secondary_group_folds(train_raw, n_splits=5, group_col=\"id_client\")\n\nvalidate_folds_disjoint(folds_primary, check_full_coverage=False)\nvalidate_folds_disjoint(folds_secondary, check_full_coverage=True, n_rows=len(train_raw))\n\nprint(\"Primary folds:\", {k: (len(v[0]), len(v[1])) for k, v in folds_primary.items()})\nprint(\"Secondary folds:\", {k: (len(v[0]), len(v[1])) for k, v in folds_secondary.items()})\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "export_fold_artifacts(\n    train=train_raw,\n    primary_folds=folds_primary,\n    secondary_folds=folds_secondary,\n    output_dir=ARTIFACT_DIR,\n)\n\n# Artefacts complémentaires\npd.DataFrame({\"cat_col\": bundle.cat_cols}).to_csv(ARTIFACT_DIR / \"cat_cols.csv\", index=False)\npd.DataFrame({\"feature_col\": bundle.feature_cols}).to_csv(\n    ARTIFACT_DIR / \"feature_cols.csv\", index=False\n)\n\ntarget_df = pd.DataFrame({\n    \"row_idx\": np.arange(len(bundle.y_freq), dtype=int),\n    \"index\": train_raw[INDEX_COL].to_numpy(),\n    \"y_freq\": bundle.y_freq.to_numpy(),\n    \"y_sev\": bundle.y_sev.to_numpy(),\n})\ntarget_df.to_parquet(ARTIFACT_DIR / \"y_train_targets.parquet\", index=False)\n\nmeta = {\n    \"data_dir\": str(DATA_DIR),\n    \"n_train\": int(len(train_raw)),\n    \"n_test\": int(len(test_raw)),\n    \"n_features\": int(len(bundle.feature_cols)),\n    \"n_cat\": int(len(bundle.cat_cols)),\n    \"primary_folds\": [int(k) for k in sorted(folds_primary.keys())],\n    \"secondary_folds\": [int(k) for k in sorted(folds_secondary.keys())],\n}\n(ARTIFACT_DIR / \"dataset_meta.json\").write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n\nprint(\"Saved:\")\nprint(\"-\", ARTIFACT_DIR / \"folds_primary.parquet\")\nprint(\"-\", ARTIFACT_DIR / \"folds_secondary.parquet\")\nprint(\"-\", ARTIFACT_DIR / \"cat_cols.csv\")\nprint(\"-\", ARTIFACT_DIR / \"feature_cols.csv\")\nprint(\"-\", ARTIFACT_DIR / \"y_train_targets.parquet\")\nprint(\"-\", ARTIFACT_DIR / \"dataset_meta.json\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Notes\n- `folds_primary` est un schéma temporel forward-chaining (4 folds valides sur 5 blocs).\n- `folds_secondary` couvre 100% des lignes avec disjonction par `id_client`.\n- On garde ces 2 splits pour la suite (`02_modeling_3_engines.ipynb`).\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}