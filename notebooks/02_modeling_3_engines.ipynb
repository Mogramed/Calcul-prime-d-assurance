{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 02 — Modeling 3 Engines (CatBoost / LightGBM / XGBoost)\n\nCe notebook exécute:\n- pipeline fréquence + gravité 2-parties,\n- variantes gravité (`classic`, `weighted_tail`),\n- calibration fréquence (`none`, `isotonic`, `platt`),\n- évaluations primaire + secondaire,\n- logging artefacts (`run_registry.csv`, `oof_predictions.parquet`).\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import sys\nfrom pathlib import Path\nimport itertools\nimport json\nimport numpy as np\nimport pandas as pd\n\nROOT = Path.cwd()\nif not (ROOT / \"src\").exists():\n    ROOT = ROOT.parent\nif str(ROOT) not in sys.path:\n    sys.path.insert(0, str(ROOT))\n\nfrom src.v1_pipeline import (\n    COARSE_CONFIGS,\n    INDEX_COL,\n    ensure_dir,\n    load_train_test,\n    prepare_datasets,\n    run_cv_experiment,\n    pick_top_configs,\n    save_json,\n)\n\nDATA_DIR = ROOT / \"data\"\nARTIFACT_DIR = ensure_dir(ROOT / \"artifacts\")\n\n# Runtime controls\nRUN_FULL = False      # True => 3 moteurs robustes complets (2-4h+)\nQUICK_TOPK_CONFIG = 1 # en mode rapide, ne garde que N config/moteur\n\nSEEDS = [42, 2026] if RUN_FULL else [42]\nSEVERITY_MODES = [\"classic\", \"weighted_tail\"] if RUN_FULL else [\"classic\", \"weighted_tail\"]\nCALIBRATION_METHODS = [\"none\", \"isotonic\", \"platt\"] if RUN_FULL else [\"none\", \"isotonic\"]\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def frame_to_folds(df: pd.DataFrame):\n    folds = {}\n    for fold_id, g in df.groupby(\"fold_id\"):\n        tr = g.loc[g[\"role\"] == \"train\", \"row_idx\"].to_numpy(dtype=int)\n        va = g.loc[g[\"role\"] == \"valid\", \"row_idx\"].to_numpy(dtype=int)\n        folds[int(fold_id)] = (tr, va)\n    return folds\n\ntrain_raw, test_raw = load_train_test(DATA_DIR)\nbundle = prepare_datasets(train_raw, test_raw, drop_identifiers=True)\n\nfolds_primary_df = pd.read_parquet(ARTIFACT_DIR / \"folds_primary.parquet\")\nfolds_secondary_df = pd.read_parquet(ARTIFACT_DIR / \"folds_secondary.parquet\")\n\nfolds_primary = frame_to_folds(folds_primary_df)\nfolds_secondary = frame_to_folds(folds_secondary_df)\n\nsplits = {\n    \"primary_time\": folds_primary,\n    \"secondary_group\": folds_secondary,\n}\n\nprint(\"Splits loaded:\", {k: len(v) for k, v in splits.items()})\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Execution loop\nall_fold_metrics = []\nall_run_metrics = []\nall_pred_frames = []\n\nfor split_name, folds in splits.items():\n    for engine, cfgs in COARSE_CONFIGS.items():\n        engine_cfgs = cfgs if RUN_FULL else cfgs[:QUICK_TOPK_CONFIG]\n        for cfg in engine_cfgs:\n            for severity_mode in SEVERITY_MODES:\n                for seed in SEEDS:\n                    print(\n                        f\"[RUN] split={split_name} engine={engine} cfg={cfg['config_id']} \"\n                        f\"sev={severity_mode} seed={seed}\"\n                    )\n\n                    fold_df, run_df, pred_df = run_cv_experiment(\n                        split_name=split_name,\n                        engine=engine,\n                        config_id=cfg[\"config_id\"],\n                        X=bundle.X_train,\n                        y_freq=bundle.y_freq,\n                        y_sev=bundle.y_sev,\n                        folds=folds,\n                        X_test=bundle.X_test,\n                        cat_cols=bundle.cat_cols,\n                        seed=seed,\n                        severity_mode=severity_mode,\n                        calibration_methods=CALIBRATION_METHODS,\n                        freq_params=cfg[\"freq_params\"],\n                        sev_params=cfg[\"sev_params\"],\n                    )\n                    all_fold_metrics.append(fold_df)\n                    all_run_metrics.append(run_df)\n                    all_pred_frames.append(pred_df)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "fold_metrics = pd.concat(all_fold_metrics, ignore_index=True) if all_fold_metrics else pd.DataFrame()\nrun_metrics = pd.concat(all_run_metrics, ignore_index=True) if all_run_metrics else pd.DataFrame()\npreds = pd.concat(all_pred_frames, ignore_index=True) if all_pred_frames else pd.DataFrame()\n\nregistry = pd.concat([fold_metrics, run_metrics], ignore_index=True)\nregistry.to_csv(ARTIFACT_DIR / \"run_registry.csv\", index=False)\npreds.to_parquet(ARTIFACT_DIR / \"oof_predictions.parquet\", index=False)\n\ntest_preds = preds[preds[\"is_test\"] == 1].copy()\ntest_preds.to_parquet(ARTIFACT_DIR / \"test_predictions.parquet\", index=False)\n\nprint(\"Saved:\")\nprint(\"-\", ARTIFACT_DIR / \"run_registry.csv\")\nprint(\"-\", ARTIFACT_DIR / \"oof_predictions.parquet\")\nprint(\"-\", ARTIFACT_DIR / \"test_predictions.parquet\")\nprint(\"Registry rows:\", len(registry), \"| Pred rows:\", len(preds))\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Sélection top configs par moteur (sur split primaire)\nselected_configs = pick_top_configs(\n    run_registry=run_metrics,\n    split_name=\"primary_time\",\n    top_k_per_engine=2 if RUN_FULL else 1,\n)\nsave_json(selected_configs, ARTIFACT_DIR / \"selected_configs.json\")\nselected_configs\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Résumé principal\nsummary_primary = (\n    run_metrics[run_metrics[\"split\"] == \"primary_time\"]\n    .sort_values([\"rmse_prime\", \"brier_freq\"])\n    .head(20)\n)\nsummary_secondary = (\n    run_metrics[run_metrics[\"split\"] == \"secondary_group\"]\n    .sort_values([\"rmse_prime\", \"brier_freq\"])\n    .head(20)\n)\n\nprint(\"Top primary:\")\ndisplay(summary_primary)\nprint(\"Top secondary:\")\ndisplay(summary_secondary)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Artefacts produits\n- `artifacts/run_registry.csv`\n- `artifacts/oof_predictions.parquet`\n- `artifacts/test_predictions.parquet`\n- `artifacts/selected_configs.json`\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}